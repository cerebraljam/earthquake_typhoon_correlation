{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are Typhoon Causing Earthquakes? Testing between 2 hypotheses\n",
    "\n",
    "tl;dr: I still have doubts, but... it does seem so?\n",
    "\n",
    "Saturday October 12th 2019, the Super Typhoon 19 has hit Japan. While chatting online with my friends, I asked if it was more likely to have earthquakes during typhoons than it is normally. One of my friend told me that \n",
    "\n",
    "> On theory is that thereâ€™s actually a confounding going on. Both earthquakes, typhoons, lightning storms being in part driven by cosmic radiation. According to the theory such radiation gets amplified at certain time of year, roughly March and September. So, the impact to earths magnetic field is larger then. 3-11 Tohoku earthquake was in March. Could be coincidence but take a look at the timings of large earthquakes and you will see some bias toward these times of year. \n",
    "\n",
    "> Refering to [Australian Geographic](https://www.australiangeographic.com.au/topics/science-environment/2011/03/earthquakes-the-10-biggest-in-history/), out of the 10 largest, 3 are in March and one in end of Feb. 4/12 could be by chance of course.\n",
    "\n",
    "On this, I decided to test both hypotheses:\n",
    "* Earthquakes could be driven by cosmic radiations, roughly around March and September\n",
    "* There is a higher chance of earthquakes during typhoons.\n",
    "\n",
    "While toying around with the first hypothesis: 18:21:53 JPT, Chiba was hit by a M5.7 Shindo 4 earthquake, which strangely privided evidences for my initial hypothesis, but was it really?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 1: Earthquakes could be driven by cosmic radiations, roughly around March and September\n",
    "\n",
    "Using the data from Australian Geographic, we can check if it is significant:\n",
    "\n",
    "* Hypothesis 1: There are more major earthquakes in March and September. The sample is quite limited (5, 3, 12, 3, 11, 2, 1, 4, 3, 8). Still, we can try anyway. \n",
    "\n",
    "* Hypothesis 2: The opposing hypothesis is that there is no relation and that earthquakes are relatively random\n",
    "\n",
    "To test this, I will oppose the odds of both hypotheses. Earthquakes happening more often in March and September is the equivalent of throwing loaded dice: \n",
    "* h1 (`(1/6)^4 + (5/6)^6`) should be much greater than h2 (`(1/12)^4 + (11/12)^6)`) if cosmic radiations have an impact.\n",
    "* Otherwise, the ratios should be quite close\n",
    "\n",
    "How does this calculation works? For more details, have a look at Will Kurt's book [Bayesian Statistics the Fun Way](https://www.amazon.co.jp/Bayesian-Statistics-Fun-Will-Kurt/dp/1593279566/ref=sr_1_1?keywords=bayesian+the+fun+way&qid=1571041389&sr=8-1), or his blog article [Bayesian Reasoning in The Twilight Zone!](https://www.countbayesie.com/blog/2016/3/16/bayesian-reasoning-in-the-twilight-zone)\n",
    "\n",
    "If this I am using Bayesian Factors, where are the priors? Any prior would have done, but let's be skeptical: 1:10 seems reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 4, beta: 17\n",
      "* Probability of h1 with alpha 4 and beta 17: 3.477873773945179e-05\n",
      "* Probability of having all the events uniforally distributed with the same alpha/beta: 1.0986756028351329e-05\n",
      "* Probability that H1 explains more observed data than H2: 3.165514702402169\n",
      "  * Looks like we're on something\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "# We start by counting the values of Alpha and Beta:\n",
    "# Alpha being the number of times the earthquake values hits March or September\n",
    "# Beta is when it fails to match\n",
    "def evaluate_alphabeta(hits, values, a, b):\n",
    "    for m in values:\n",
    "        if m in hits:\n",
    "            a+=1\n",
    "        else:\n",
    "            b+=1\n",
    "    return a, b\n",
    "\n",
    "# Then we compare against\n",
    "def evaluate_odds(hit, value, a, b, comment=True):\n",
    "\n",
    "    # P(D|h1) \n",
    "    x = beta.stats(hit, value - hit, moments='m') # probability of hits among the sample\n",
    "    h1 = np.power(x, a) * np.power(1 - x, b)\n",
    "#     print(hit, value - hit, x, h1)\n",
    "\n",
    "    # P(D|h2) \n",
    "    y = beta.stats(1, value - 1, moments='m') # probability that it is random (1 / 12)\n",
    "    \n",
    "    h2 = np.power(y, a) * np.power(1 - y, b)\n",
    "#     print(1, value - 1, y, h2)\n",
    "    \n",
    "    # P(D|H1) / P(D|H2)\n",
    "    o = h1/h2\n",
    "    if comment:\n",
    "        print('* Probability of h1 with alpha {} and beta {}: {}'.format(a, b, h1))\n",
    "        print('* Probability of having all the events uniforally distributed with the same alpha/beta: {}'.format(h2))\n",
    "        print('* Probability that H1 explains more observed data than H2: {}'.format(o))\n",
    "        \n",
    "    return o\n",
    "\n",
    "def comment_odds(o):\n",
    "    if o < 1:\n",
    "        return 'Nothing interesting'\n",
    "    if 1 <= o and o < 3:\n",
    "        return 'Interesting, but nothing conclusive'\n",
    "    elif 3 <= o and o < 20:\n",
    "        return \"Looks like we're on something\"\n",
    "    elif 20 <= o and o < 150:\n",
    "        return \"Strong evidence in favor of H1\"\n",
    "    elif 150 <= o:\n",
    "        return \"Overwhelming evidence\"\n",
    "\n",
    "# months of earthquakes from https://www.australiangeographic.com.au/topics/science-environment/2011/03/earthquakes-the-10-biggest-in-history/\n",
    "majors = [5, 3, 12, 3, 11, 2, 1, 4, 3, 8]\n",
    "valids = [x+1 for x in range(12)]\n",
    "\n",
    "hits = [3, 9] # the hypothesis is that earthquakes happens more often in March and September\n",
    "\n",
    "# prior odds of 1 success for 2 failure\n",
    "prior_a = 1 # prior alpha\n",
    "prior_b = 10 # prior beta\n",
    "\n",
    "a, b = evaluate_alphabeta(hits, majors, prior_a, prior_b)\n",
    "\n",
    "print('alpha: {}, beta: {}'.format(a, b))\n",
    "o = evaluate_odds(2, 12, a, b)\n",
    "print(\"  * {}\".format(comment_odds(o)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It seems that h1 slightly better explain the observations than h2. But how about if we try with more earthquakes?\n",
    "\n",
    "## Testing with more data\n",
    "For this next test, I used the [earthquake dataset available on Kaggle](https://www.kaggle.com/usgs/earthquake-database).\n",
    "\n",
    "First I need to adjust the data to suite the checks, by converting the date in string into a datetime format, then adding a column Month that contains only the month number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23412\n"
     ]
    }
   ],
   "source": [
    "df_eq = pd.read_csv('earthquake-database.csv')\n",
    "df_eq['Month'] = 0\n",
    "\n",
    "for i, r in df_eq.iterrows():\n",
    "    s = r['Date']\n",
    "    try:\n",
    "        d = datetime.datetime.strptime(s, '%m/%d/%Y')\n",
    "    except:\n",
    "        d = datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    df_eq.at[i, 'Date'] = d\n",
    "    df_eq.at[i, 'Month'] = d.month\n",
    "\n",
    "print(len(df_eq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just replace the data from Australian Geographic with the values from the Dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 69, beta: 389\n",
      "* Probability of h1 with alpha 69 and beta 389: 3.206705015102759e-85\n",
      "* Probability of having all the events uniforally distributed with the same alpha/beta: 6.866633006340007e-90\n",
      "* Probability that H1 explains more observed data than H2: 46699.81652058567\n",
      "  * Overwhelming evidence\n"
     ]
    }
   ],
   "source": [
    "magnitude=7.2\n",
    "\n",
    "majors = list(df_eq[df_eq['Magnitude'] >= magnitude]['Month'])\n",
    "valids = [x+1 for x in range(12)]\n",
    "\n",
    "hits = [3, 9] # the hypothesis is that earthquakes happens more often in March and September\n",
    "\n",
    "a, b = evaluate_alphabeta(hits, majors, prior_a, prior_b)\n",
    "print('alpha: {}, beta: {}'.format(a, b))\n",
    "k1 = evaluate_odds(2, 12, a, b)\n",
    "print(\"  * {}\".format(comment_odds(k1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwhelming evidences? Really? What if we try with other months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 63, beta: 395\n",
      "* Probability of h1 with alpha 63 and beta 395: 5.010476586098064e-81\n",
      "* Probability of having all the events uniforally distributed with the same alpha/beta: 1.216465923534471e-83\n",
      "* Probability that H1 explains more observed data than H2: 411.88795256508325\n",
      "  * Overwhelming evidence\n"
     ]
    }
   ],
   "source": [
    "majors = list(df_eq[df_eq['Magnitude'] >= magnitude]['Month'])\n",
    "hits = [1, 6] # the hypothesis is that earthquakes happens more often in March and September\n",
    "\n",
    "a, b = evaluate_alphabeta(hits, majors, prior_a, prior_b)\n",
    "print('alpha: {}, beta: {}'.format(a, b))\n",
    "k2 = evaluate_odds(2, 12, a, b)\n",
    "print(\"  * {}\".format(comment_odds(k2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh oh, January and June also provide overwhelming evidences even better suite the data we have. This tells us that we can't simply blindly say \"Yeah, Cosmic Radiations, mainly happening in March and September, causes earthquakes\". We need more tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 vs k2 (113.37990399999995): Strong evidence in favor of H1\n",
      "k2 vs k1 (0.008819905157090276): Nothing interesting\n"
     ]
    }
   ],
   "source": [
    "print(\"k1 vs k2 ({}): {}\".format(k1/k2, comment_odds(k1/k2)))\n",
    "print(\"k2 vs k1 ({}): {}\".format(k2/k1, comment_odds(k2/k1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hummm, k1 (Hypothesis 1 with kaggle data) seems far superior over k2. How about the other months? Testing all of them by hand would be quite bothering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best hypotheses using Monte Carlo Simulations\n",
    "\n",
    "The cell below is probably way too complicated for what it needs to be, but because of the large quantity of earthquakes in the Kaggle database, running the `evaluate_odds` function on all will case overflows. To go around this, I run 1000 simulations of 400 samples for each pairs of months, then I make an average of the results to evaluate the more likely value. Since there are only 450 earthquakes of 7.2 and higher, it should tend to the average relatively quickly. Still, we can later run this simulation on smaller earthquakes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def monte_carlo_simulation(simulation, sample, lists, prior_a, prior_b):\n",
    "    outcome = {}\n",
    "    print('Checking our hypothesis against {} simulations of {} random samples of earthquakes >= {} ({})'.format(simulation, sample, magnitude, len(list(df_eq[df_eq['Magnitude'] >= magnitude]['Month']))))\n",
    "    print('My priors are that there is a {} chance against {} that there is a relation between earthquakes and months'.format(prior_a, prior_b))\n",
    "    for x in range(1, 12):\n",
    "        for y in range(x+1, 13):\n",
    "            candidates = [x, y]\n",
    "            xy = \",\".join([str(x), str(y)])\n",
    "\n",
    "            for i in range(simulation):\n",
    "                earthquakes = np.random.choice(lists, sample)\n",
    "\n",
    "                a, b = evaluate_alphabeta(candidates, earthquakes, prior_a, prior_b)\n",
    "\n",
    "                o = evaluate_odds(2, 12, a, b, False)\n",
    "\n",
    "                if xy not in outcome.keys():\n",
    "                    outcome[xy] = np.empty(0)\n",
    "\n",
    "                outcome[xy] = np.append(outcome[xy], o)\n",
    "    report = {}\n",
    "    for xy in outcome.keys():\n",
    "        if outcome[xy].mean() not in report.keys():\n",
    "            report[outcome[xy].mean()] = []\n",
    "        report[outcome[xy].mean()].append(xy)\n",
    "\n",
    "    print(\"Average of the odds from all the pair of months: {}: {}\".format(np.array(list(report.keys())).mean(), comment_odds(np.array(list(report.keys())).mean())))\n",
    "    for s in sorted(report.keys(), reverse=True)[:10]:\n",
    "        print(\"{}: {}: {}\".format(s, report[s], comment_odds(s)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking our hypothesis against 1000 simulations of 400 random samples of earthquakes >= 7.2 (447)\n",
      "My priors are that there is a 1 chance against 10 that there is a relation between earthquakes and months\n",
      "Average of the odds from all the pair of months: 1.2284758425423486e+16: Overwhelming evidence\n",
      "5.779371685352091e+17: ['8,11']: Overwhelming evidence\n",
      "9.342710423650088e+16: ['7,8']: Overwhelming evidence\n",
      "8.16286301178623e+16: ['8,10']: Overwhelming evidence\n",
      "1.9752444587255828e+16: ['4,8']: Overwhelming evidence\n",
      "1.5072594329784692e+16: ['7,10']: Overwhelming evidence\n",
      "1.0061870558221028e+16: ['10,11']: Overwhelming evidence\n",
      "6937988395712142.0: ['8,12']: Overwhelming evidence\n",
      "2064518783866544.5: ['10,12']: Overwhelming evidence\n",
      "929426757591021.6: ['7,11']: Overwhelming evidence\n",
      "830093137109461.6: ['5,8']: Overwhelming evidence\n"
     ]
    }
   ],
   "source": [
    "simulation = 1000\n",
    "sample = 400\n",
    "\n",
    "monte_carlo_simulation(simulation, sample, list(df_eq[df_eq['Magnitude'] >= magnitude]['Month']), prior_a, prior_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they are all `Overwhelming evidence`, even the average. This tells us one thing useful: if the sample size is too great, this method of comparing odds degenerates. \n",
    "\n",
    "Running the simulation on a smaller sample gives more reasonable results, but it doesn't change the fact that all results are still quite similar, and not singling out one hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking our hypothesis against 1000 simulations of 10 random samples of earthquakes >= 7.2 (447)\n",
      "My priors are that there is a 1 chance against 10 that there is a relation between earthquakes and months\n",
      "Average of the odds from all the pair of months: 1.8675423313931643: Interesting, but nothing conclusive\n",
      "2.6059439277078655: ['8,12']: Interesting, but nothing conclusive\n",
      "2.5572177606518767: ['8,11']: Interesting, but nothing conclusive\n",
      "2.431827053263679: ['7,8']: Interesting, but nothing conclusive\n",
      "2.3995761673128357: ['8,10']: Interesting, but nothing conclusive\n",
      "2.391082104372601: ['7,12']: Interesting, but nothing conclusive\n",
      "2.339472435488872: ['5,7']: Interesting, but nothing conclusive\n",
      "2.33555918007478: ['10,11']: Interesting, but nothing conclusive\n",
      "2.3313243407117774: ['7,11']: Interesting, but nothing conclusive\n",
      "2.284441807471236: ['3,8']: Interesting, but nothing conclusive\n",
      "2.2414130531671916: ['10,12']: Interesting, but nothing conclusive\n"
     ]
    }
   ],
   "source": [
    "simulation = 1000\n",
    "sample = 10\n",
    "\n",
    "monte_carlo_simulation(simulation, sample, list(df_eq[df_eq['Magnitude'] >= magnitude]['Month']), prior_a, prior_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the simulation end up with the same evaluation `Interesting, but not conclusive`, including the average. \n",
    "\n",
    "From the data available, it doesn't seems like Cosmic Radiations have a significant impact on earthquakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2: There is a higher chance of earthquakes during typhoons.\n",
    "\n",
    "The second hypothesis was that Typhoon could cause earthquakes. To test this hypothesis, I used the [Hurricaine dataset from Kaggle](https://www.kaggle.com/noaa/hurricane-database). \n",
    "\n",
    "Since there are more earthquakes in the Pasific than the Atlantic ocean, I limited the longitude between Bangkok and the Marshall Islands. This is arbitray, but considering the size of typhoons and their strenght, it could be arguable that their effect could extend on long distances.\n",
    "\n",
    "First, we need to load the dataset, fix the dates, longitudes and latitudes to match the Earthquake dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_typhoon = pd.read_csv('typhoon-pacific.csv')\n",
    "\n",
    "df_typhoon['Month'] = 0\n",
    "longitude_min = 129 #Bangkook\n",
    "longitude_max = 163 #Marshall Islands\n",
    "\n",
    "\n",
    "for i, r in df_typhoon.iterrows():\n",
    "    s = str(r['Date'])\n",
    "    d = datetime.datetime.strptime(s, '%Y%m%d')\n",
    "    df_typhoon.at[i, 'Date'] = d\n",
    "    \n",
    "    la = r['Latitude']\n",
    "    letter = la[len(la)-1:]\n",
    "    la_coordinate = float(la[:len(la)-1])\n",
    "    if letter == 'S':\n",
    "        la_coordinate*= -1\n",
    "    \n",
    "    lo = r['Longitude']\n",
    "    letter = lo[len(lo)-1:]\n",
    "    lo_coordinate = float(lo[:len(lo)-1])\n",
    "    \n",
    "    if letter == 'E':\n",
    "        lo_coordinate*= -1\n",
    "    \n",
    "    df_typhoon.at[i, 'Latitude'] = float(la_coordinate)\n",
    "    df_typhoon.at[i, 'Longitude'] = float(lo_coordinate)\n",
    "\n",
    "# We need to limit the typhoon and earthquake dataset to their overlapping periods\n",
    "df_typhoon_period = df_typhoon[(df_typhoon['Longitude'] >= 129) & (df_typhoon['Longitude'] <= 163) & (df_typhoon['Date'] >= min(df_eq['Date']))]\n",
    "df_eq_period = df_eq[(df_eq['Longitude'] >= 129) & (df_eq['Longitude'] <= 163) & (df_eq['Date'] <= max(df_typhoon['Date']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data prepared, I can prepare the values to run the same tests as for the earthquakes and cosmic radiations.\n",
    "\n",
    "* condition for a: There is an earthquake the same day as a typhoon\n",
    "* condition for b: There is a typhoon without an earthquake\n",
    "\n",
    "but before starting, I want to update my prior: I do think that it is unlikely that typhoon causes earthquakes. 1:100 seems like reasonable prior odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 earthquakes, 7 collisions with typhoons, 104 misses\n",
      "1335 typhoons, 7 collisions with earthquakes, 1328 misses\n",
      "\n",
      "alpha: 8, beta: 1428\n",
      "* Probability of h1 with alpha 8 and beta 1428: 3.137169035292566e-22\n",
      "* Probability of having all the events uniforally distributed with the same alpha/beta: 3.399594319915749e-26\n",
      "* Probability that H1 explains more observed data than H2: 9228.06882254796\n",
      "Bayes factor between the hypothesis and randomness: 9228.06882254796: Overwhelming evidence\n"
     ]
    }
   ],
   "source": [
    "prior_a = 1\n",
    "prior_b = 100\n",
    "\n",
    "\n",
    "typhoons = df_typhoon_period['Date'].unique()\n",
    "earthquakes = df_eq_period[(df_eq_period['Magnitude'] >= magnitude)]['Date'].unique()\n",
    "\n",
    "e_hits = df_eq_period[(df_eq_period['Date'].isin(list(typhoons))) & (df_eq_period['Magnitude'] >= magnitude)]['Date'].unique()\n",
    "e_misses = df_eq_period[(~df_eq_period['Date'].isin(list(typhoons))) & (df_eq_period['Magnitude'] >= magnitude)]['Date'].unique()\n",
    "\n",
    "t_hits = df_typhoon_period[df_typhoon_period['Date'].isin(earthquakes)]['Date'].unique()\n",
    "t_misses = df_typhoon_period[~df_typhoon_period['Date'].isin(earthquakes)]['Date'].unique()\n",
    "\n",
    "a, b = evaluate_alphabeta(e_hits, typhoons, prior_a, prior_b)\n",
    "print(\"{} earthquakes, {} collisions with typhoons, {} misses\".format(len(earthquakes), len(e_hits), len(e_misses)))\n",
    "print(\"{} typhoons, {} collisions with earthquakes, {} misses\".format(len(typhoons), len(t_hits), len(t_misses)))\n",
    "\n",
    "\n",
    "print('\\nalpha: {}, beta: {}'.format(a, b))\n",
    "# print('\\n{} earthquakes during the period, {} typhoon during the same period, a: {}, b: {}'.format(len(earthquakes), len(typhoons), a, b))\n",
    "\n",
    "\n",
    "k3 = evaluate_odds(len(e_hits), len(typhoons), a, b)\n",
    "print(\"Bayes factor between the hypothesis and randomness: {}: {}\".format(k3, comment_odds(k3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Overwhelming evidences`? This could also be distorted by the large sample, but opposed to the correlation with the months, there is little space for mistake here. Are we really on something here?\n",
    "\n",
    "If we do the same calculation, but with typhoon colliding with earthquakes. In both cases, we know that there are 7 collisions, but because there is less strong earthquakes than typhoons, the odds should be more significatif:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 8, beta: 204\n",
      "* Probability of h1 with alpha 8 and beta 204: 4.2375421814114814e-16\n",
      "* Probability of having all the events uniforally distributed with the same alpha/beta: 6.849143564182111e-18\n",
      "* Probability that H1 explains more observed data than H2: 61.869665042092116\n",
      "Bayes factor between the hypothesis and randomness: 61.869665042092116: Strong evidence in favor of H1\n"
     ]
    }
   ],
   "source": [
    "a, b = evaluate_alphabeta(t_hits, earthquakes, prior_a, prior_b)\n",
    "\n",
    "print('alpha: {}, beta: {}'.format(a, b))\n",
    "\n",
    "k4 = evaluate_odds(len(t_hits), len(earthquakes), a, b)\n",
    "print(\"Bayes factor between the hypothesis and randomness: {}: {}\".format(k4, comment_odds(k4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Well, from the datasets we have, longitude restrictions, and the earthquake size I chose, it seems that there might be `Strong evidences` that typhoons might influence earthquakes.\n",
    "\n",
    "... I am so surprised. Are we really on to something?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
